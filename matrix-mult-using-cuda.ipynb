{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%writefile matrix_mul.cu\n\n#include <stdio.h>\n#include <cuda_runtime.h>\n\n// Matrix dimensions\n#define M 512  // Rows of A and C\n#define K 512  // Cols of A, Rows of B\n#define N 512  // Cols of B and C\n\n__global__ void matMulKernel(float *A, float *B, float *C, int m, int n, int k) {\n    int row = blockIdx.y * blockDim.y + threadIdx.y;\n    int col = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (row < m && col < n) {\n        float sum = 0.0f;\n        for (int i = 0; i < k; ++i) {\n            sum += A[row * k + i] * B[i * n + col];\n        }\n        C[row * n + col] = sum;\n    }\n}\n\nint main() {\n    size_t sizeA = M * K * sizeof(float);\n    size_t sizeB = K * N * sizeof(float);\n    size_t sizeC = M * N * sizeof(float);\n\n    float *h_A = (float *)malloc(sizeA);\n    float *h_B = (float *)malloc(sizeB);\n    float *h_C = (float *)malloc(sizeC);\n\n    // Initialize host matrices with 1.0\n    for (int i = 0; i < M * K; ++i) h_A[i] = 1.0f;\n    for (int i = 0; i < K * N; ++i) h_B[i] = 1.0f;\n\n    float *d_A, *d_B, *d_C;\n    cudaMalloc(&d_A, sizeA);\n    cudaMalloc(&d_B, sizeB);\n    cudaMalloc(&d_C, sizeC);\n\n    cudaMemcpy(d_A, h_A, sizeA, cudaMemcpyHostToDevice);\n    cudaMemcpy(d_B, h_B, sizeB, cudaMemcpyHostToDevice);\n\n    dim3 block(16, 16);\n    dim3 grid((N + block.x - 1) / block.x,\n              (M + block.y - 1) / block.y);\n\n    // Correct function call with constants M, N, K passed as arguments\n    matMulKernel<<<grid, block>>>(d_A, d_B, d_C, M, N, K);\n    cudaDeviceSynchronize();\n\n    cudaMemcpy(h_C, d_C, sizeC, cudaMemcpyDeviceToHost);\n\n    // Print first element (should be 512.0 if all inputs were 1.0)\n    printf(\"C[0] = %f\\\\n\", h_C[0]);\n\n    // Free memory\n    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);\n    free(h_A); free(h_B); free(h_C);\n\n    return 0;\n}\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-02T18:23:24.802559Z","iopub.execute_input":"2025-07-02T18:23:24.803182Z","iopub.status.idle":"2025-07-02T18:23:24.809210Z","shell.execute_reply.started":"2025-07-02T18:23:24.803146Z","shell.execute_reply":"2025-07-02T18:23:24.808475Z"}},"outputs":[{"name":"stdout","text":"Overwriting matrix_mul.cu\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!nvcc -o matrix_mul matrix_mul.cu\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T18:23:26.740809Z","iopub.execute_input":"2025-07-02T18:23:26.741297Z","iopub.status.idle":"2025-07-02T18:23:28.623875Z","shell.execute_reply.started":"2025-07-02T18:23:26.741273Z","shell.execute_reply":"2025-07-02T18:23:28.623127Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"!./matrix_mul\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T18:23:29.746718Z","iopub.execute_input":"2025-07-02T18:23:29.747440Z","iopub.status.idle":"2025-07-02T18:23:30.230018Z","shell.execute_reply.started":"2025-07-02T18:23:29.747407Z","shell.execute_reply":"2025-07-02T18:23:30.229332Z"}},"outputs":[{"name":"stdout","text":"C[0] = 512.000000\\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}